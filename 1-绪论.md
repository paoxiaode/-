## 1-绪论

### 机器学习概念基础

- **iid 独立同分布**

  训练样本与测试样本独立同分布

- 监督/无监督

- 算法：回归/分类/聚类 

  判断年龄---回归，年龄区间---分类

- 样本张成样本空间

- 特征组成特征向量，向量张成特征空间

  好的特征invariance：平移、旋转不变性

  



### 泛化、训练误差

最小化训练误差为了最小化泛化误差（iid）

评估泛化好坏：欠拟合、过拟合

**过拟合：模型在测试集上效果很差，在训练集上效果很好**

* 原因
  * 训练集和测试机特征分布不一致
  * 模型复杂而训练数据不足
* 解决方案
  * 增加训练数据
  * 正则化（L1: Lasso, L2: Ridge)
  * Dropout



### 模型评估

* 留出法（hold-out)

  直接将数据集划分为两个互斥的子集（训练+测试）

  * 测试集一般为训练集的1/5

  

* 交叉验证法（cross entropy）

  将数据集分层多次采样，每次划分为多个互斥的子集

  * 会产生多个模型，要训练很多次

    

* 自助法（bootstrap）

  有放回的采样，数据集中m个样本，有放回取m次。

  大约有36.8%的数据未出现 (1-1/m)^m

  * 适合于小规模，训练集存在重复

### 性能度量

* 回归任务（均方误差）

  公式：

* 分类任务（错误率和精度accuracy）

  **不同错误代价可能不一样（多分类）**

  公式：

#### 真阳率、假阳率

**通过率 = TP/(TP+FN)**    (正样本有多少正确识别)

**假阳率 = FP/(FP+TN)**



#### ROC 曲线



<img src="imag\图片1.png" alt="图片1" style="zoom: 33%;" />

* AUC: ROC曲线下的面积（越大越好）
* 随着假阳率的上升，意味着样本越容易通过
* 理想情况，通过率高，假阳率低（绿线更好）



#### Precision查准、recall查全

**precision = TP/(TP+FP)**

**recall = TP/(TP+FN)** (和通过率一样)

<img src="imag\图片2.png" alt="图片1" style="zoom: 67%;" />

* A优于C
* recall上升，通过阈值下降，精度下降
* 精度上升，通过阈值上升，recall下降

### Error

$$
Error = noise+bias+variance
$$

noise：原始数据标签误差

bias：本身/系统性误差，模型不对

variance：**多个拟合预测之间的偏离程度**，数据采样的问题，模型越复杂越大



### 偏差-方差分解

<img src=".\imag\图片3.png" alt="图片1" style="zoom: 67%;" />

**Low bias – 复杂化模型 – 过拟合 – high variance – 分散**

**Low variance – 简单化模型 – 欠拟合 – high bias – 偏离中心**











